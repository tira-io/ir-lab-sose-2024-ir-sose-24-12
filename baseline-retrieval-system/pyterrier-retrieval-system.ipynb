{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run, ir_datasets\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "from pyterrier_pisa import PisaIndex\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "pt_index_path = './terrier-index'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "  # create the index, using the IterDictIndexer indexer \n",
    "  indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n",
    "\n",
    "  # we give the dataset get_corpus_iter() directly to the indexer\n",
    "  # while specifying the fields to index and the metadata to record\n",
    "  index_ref = indexer.index(pt_dataset.get_corpus_iter(), \n",
    "                            meta=('docno',))\n",
    "\n",
    "else:\n",
    "  # if you already have the index, use it.\n",
    "  index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pt.started():\n",
    "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "sdm = pt.rewrite.SDM()\n",
    "qe = pt.rewrite.Bo1QueryExpansion(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pt_dataset.get_topics(variant='title')\n",
    "qrels = pt_dataset.get_qrels()\n",
    "\n",
    "SEED=42\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
    "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)\n",
    "\n",
    "ltr_feats1 = bm25 >> pt.text.get_text(pt_dataset, [\"text\", \"doc_id\"]) >> (\n",
    "    pt.transformer.IdentityTransformer()\n",
    "    ** # sequential dependence\n",
    "    (sdm >> bm25)\n",
    "    ** # score of text (not originally indexed)\n",
    "    (pt.text.scorer(body_attr=\"text\", wmodel=\"TF_IDF\", background_index=index)) \n",
    "    ** # abstract coordinate match\n",
    "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
    ")\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames=[\"BM25\", \"SDM\", 'text', \"CoordinateMatch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:37:16.253 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   16.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 556 ms, total: 1min 45s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:   32.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "\n",
    "rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(rf)\n",
    "\n",
    "%time rf_pipe.fit(train_topics, pt_dataset.get_qrels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:38:19.524 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "---------------------------\n",
      "Training starts...\n",
      "---------------------------\n",
      "[+] Random restart #1/5...\n",
      "[+] Random restart #3/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   2|3               |    0.173|    0.619\n",
      "   0|3               |    0.228|    0.264\n",
      "   2|3               |    0.273|    0.620\n",
      "   0|3               |    0.328|    0.264\n",
      "   0|3               |    0.528|    0.266\n",
      "   2|3               |    0.473|    0.622\n",
      "   2|3               |    0.873|    0.624\n",
      "   0|3               |    0.928|    0.273\n",
      "   2|3               |    1.673|    0.626\n",
      "   0|3               |    1.728|    0.292\n",
      "   0|3               |    3.328|    0.322\n",
      "   0|3               |    6.528|    0.364\n",
      "   0|3               |   12.928|    0.379\n",
      "   2|2               |    0.022|    0.626\n",
      "   0|2               |    0.022|    0.379\n",
      "   0|2               |    0.019|    0.379\n",
      "   0|2               |    0.015|    0.380\n",
      "   0|2               |    0.058|    0.384\n",
      "   0|2               |    0.095|    0.610\n",
      "   0|2               |    0.168|    0.613\n",
      "   0|2               |    0.315|    0.616\n",
      "   0|2               |    0.608|    0.618\n",
      "   0|0               |    0.000|    0.618\n",
      "   0|0               |   -0.067|    0.619\n",
      "   2|0               |    0.283|    0.626\n",
      "   0|1               |    0.000|    0.619\n",
      "   0|1               |    0.072|    0.622\n",
      "   2|1               |   -0.078|    0.626\n",
      "   0|1               |    0.158|    0.623\n",
      "   0|1               |    5.485|    0.623\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.013|    0.623\n",
      "   0|0               |   -0.017|    0.624\n",
      "   0|0               |   -0.025|    0.624\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.072|    0.624\n",
      "   2|3               |    0.580|    0.626\n",
      "   0|0               |   -0.134|    0.624\n",
      "   0|0               |   -0.508|    0.626\n",
      "   0|1               |    0.516|    0.627\n",
      "   0|1               |    0.416|    0.636\n",
      "   0|3               |    0.078|    0.636\n",
      "   0|3               |    0.092|    0.636\n",
      "   0|3               |    0.119|    0.636\n",
      "   0|3               |    0.173|    0.637\n",
      "   0|2               |    0.000|    0.639\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   0|0               |   -0.426|    0.648\n",
      "   2|2               |    0.000|    0.626\n",
      "   2|2               |   -0.049|    0.627\n",
      "   2|2               |   -0.121|    0.627\n",
      "   0|3               |    0.106|    0.649\n",
      "   2|1               |   -0.071|    0.628\n",
      "   2|1               |   -0.064|    0.628\n",
      "   2|1               |   -0.049|    0.629\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   2|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   2|3               |    0.521|    0.629\n",
      "   2|3               |    0.421|    0.629\n",
      "   2|3               |    0.621|    0.629\n",
      "   0|2               |    0.000|    0.649\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   2|1               |   -0.045|    0.629\n",
      "[+] Random restart #4/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |    0.319|    0.631\n",
      "   3|3               |    0.219|    0.634\n",
      "   0|3               |    0.061|    0.651\n",
      "   3|1               |    0.385|    0.634\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   0|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|2               |   -0.167|    0.635\n",
      "   0|2               |    0.000|    0.651\n",
      "   3|0               |   -0.230|    0.635\n",
      "   0|3               |    0.061|    0.651\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   3|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   3|3               |    0.196|    0.635\n",
      "[+] Random restart #2/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   1|3               |    0.000|    0.616\n",
      "   1|3               |    0.015|    0.616\n",
      "   1|3               |    0.215|    0.618\n",
      "   1|3               |    0.615|    0.618\n",
      "   1|3               |    1.415|    0.621\n",
      "   1|0               |    0.011|    0.621\n",
      "   1|0               |   -0.035|    0.622\n",
      "   1|0               |    0.019|    0.622\n",
      "   1|0               |    0.022|    0.622\n",
      "[+] Random restart #5/5...\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|3               |   -0.328|    0.262\n",
      "   4|3               |   -0.428|    0.262\n",
      "   4|3               |   -0.628|    0.262\n",
      "   4|3               |   -1.028|    0.262\n",
      "   4|3               |   -1.828|    0.262\n",
      "   4|3               |   -3.428|    0.262\n",
      "   1|1               |    0.092|    0.623\n",
      "   1|1               |    0.935|    0.623\n",
      "   4|3               |    0.072|    0.262\n",
      "   4|3               |    0.472|    0.286\n",
      "   4|3               |    1.272|    0.337\n",
      "   4|3               |    2.872|    0.376\n",
      "   4|3               |    6.072|    0.380\n",
      "   4|3               |   12.472|    0.380\n",
      "   1|2               |    0.000|    0.626\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|0               |    0.017|    0.380\n",
      "   1|3               |    0.442|    0.626\n",
      "   1|3               |    0.542|    0.626\n",
      "   1|3               |    1.142|    0.627\n",
      "   1|3               |    1.942|    0.629\n",
      "   4|0               |    0.024|    0.382\n",
      "   4|0               |    0.031|    0.601\n",
      "   4|0               |    0.045|    0.623\n",
      "   4|0               |    0.073|    0.625\n",
      "   1|2               |   -0.050|    0.630\n",
      "   1|2               |   -0.150|    0.632\n",
      "   4|1               |   -0.018|    0.625\n",
      "   4|1               |   -0.007|    0.625\n",
      "   4|1               |    0.055|    0.626\n",
      "   4|1               |    0.122|    0.627\n",
      "   4|1               |    0.254|    0.627\n",
      "   1|1               |    0.253|    0.633\n",
      "   4|2               |   -0.051|    0.627\n",
      "   4|2               |   -0.082|    0.630\n",
      "   4|2               |   -0.146|    0.632\n",
      "   1|0               |    0.000|    0.633\n",
      "   1|0               |    0.003|    0.633\n",
      "   1|0               |   -0.002|    0.633\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   4|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|3               |    0.589|    0.632\n",
      "---------------------------\n",
      "Shuffle features and optimize!\n",
      "----------------------------------------\n",
      "   1|Feature         |   Weight|     NDCG\n",
      "----------------------------------------\n",
      "   4|0               |    0.050|    0.632\n",
      "   4|0               |    0.044|    0.632\n",
      "   1|0               |   -0.003|    0.633\n",
      "   1|0               |   -0.006|    0.633\n",
      "---------------------------\n",
      "Finished successfully.\n",
      "CPU times: user 1min 4s, sys: 376 ms, total: 1min 4s\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "import fastrank\n",
    "\n",
    "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
    "\n",
    "params = train_request.params\n",
    "params.init_random = True\n",
    "params.normalize = True\n",
    "params.seed = 1234567\n",
    "\n",
    "ca_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
    "\n",
    "%time ca_pipe.fit(train_topics, pt_dataset.get_qrels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:39:01.779 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "16:39:09.399 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 771\n",
      "[LightGBM] [Info] Number of data points in the train set: 47280, number of used features: 4\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's ndcg@10: 0.388735\n",
      "CPU times: user 50 s, sys: 400 ms, total: 50.4 s\n",
      "Wall time: 34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:776: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:776: UserWarning: Found 'ndcg_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:776: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# this configures LightGBM as LambdaMART\n",
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "lmart_x_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n",
    "\n",
    "%time lmart_x_pipe.fit(train_topics, pt_dataset.get_qrels(), valid_topics, pt_dataset.get_qrels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n",
      "16:39:45.318 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n",
      "16:40:25.530 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n",
      "16:41:06.187 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:776: UserWarning: Found 'ndcg_eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:776: UserWarning: Found 'ndcg_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n",
      "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:776: UserWarning: Found 'eval_at' in params. Will use it instead of 'eval_at' argument\n",
      "  _log_warning(f\"Found '{alias}' in params. Will use it instead of 'eval_at' argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "def save_results(system, name):\n",
    "    run = system(pt_dataset.get_topics('text'))\n",
    "    persist_and_normalize_run(run, system_name=name, default_output='../runs')\n",
    "    os.rename('../runs/run.txt', \"../runs/\"+name+\".txt\")\n",
    "\n",
    "save_results(bm25, \"bm25\")\n",
    "save_results(ca_pipe, \"ca_pipe\")\n",
    "save_results(rf_pipe, \"rf_pipe\")\n",
    "save_results(lmart_x_pipe, \"lmart_x_pipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:41:44.477 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "16:41:55.800 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "16:42:06.705 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "16:42:17.474 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>num_rel_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.212077</td>\n",
       "      <td>0.498089</td>\n",
       "      <td>0.362566</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDM</td>\n",
       "      <td>0.227193</td>\n",
       "      <td>0.512202</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text</td>\n",
       "      <td>0.222986</td>\n",
       "      <td>0.511401</td>\n",
       "      <td>0.375332</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoordinateMatch</td>\n",
       "      <td>0.044930</td>\n",
       "      <td>0.297142</td>\n",
       "      <td>0.023930</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name       map      ndcg  ndcg_cut_10  num_rel_ret\n",
       "0             BM25  0.212077  0.498089     0.362566        237.0\n",
       "1              SDM  0.227193  0.512202     0.388151        237.0\n",
       "2             text  0.222986  0.511401     0.375332        237.0\n",
       "3  CoordinateMatch  0.044930  0.297142     0.023930        237.0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [ltr_feats1 >> pt.ltr.feature_to_score(i) for i in range(len(fnames))],\n",
    "    test_topics,\n",
    "    qrels, \n",
    "    names=fnames,\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"num_rel_ret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
