{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "import pyterrier as pt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "pt_index_path = './terrier-index'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "  # create the index, using the IterDictIndexer indexer \n",
    "  indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n",
    "\n",
    "  # we give the dataset get_corpus_iter() directly to the indexer\n",
    "  # while specifying the fields to index and the metadata to record\n",
    "  index_ref = indexer.index(pt_dataset.get_corpus_iter(), \n",
    "                            meta=('docno',))\n",
    "\n",
    "else:\n",
    "  # if you already have the index, use it.\n",
    "  index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pt.started():\n",
    "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
    "\n",
    "configuration={\"bm25.b\": 0.1, \"bm25.k_1\": 2.5}\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls=configuration)\n",
    "sdm = pt.rewrite.SDM()\n",
    "qe = pt.rewrite.Bo1QueryExpansion(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "topics = pt_dataset.get_topics(variant='title')\n",
    "\n",
    "SEED=42\n",
    "\n",
    "!pip3 install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
    "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)\n",
    "\n",
    "ltr_feats1 = bm25 >> pt.text.get_text(pt_dataset, [\"text\", \"doc_id\"]) >> (\n",
    "    pt.transformer.IdentityTransformer()\n",
    "    ** # sequential dependence\n",
    "    (sdm >> bm25)\n",
    "    ** # score of text (not originally indexed)\n",
    "    (pt.text.scorer(body_attr=\"text\", wmodel=\"TF_IDF\", background_index=index)) \n",
    "    ** # abstract coordinate match\n",
    "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
    "    ** \n",
    "    pt.BatchRetrieve(index, wmodel=\"Js_KLs\")\n",
    ")\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames=[\"BM25\", \"SDM\", 'text', \"CoordinateMatch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m11:49:41.793 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:   54.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved to file.\n",
      "[0.2235218  0.22497675 0.27938835 0.02204656 0.25006655]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "!pip3 install joblib\n",
    "import joblib\n",
    "\n",
    "model_path = \"./model.joblib\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    # Load the model\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"Model loaded from file.\")\n",
    "    rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(model)\n",
    "else:\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "    rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(model)\n",
    "    rf_pipe.fit(train_topics, pt_dataset.get_qrels())\n",
    "    joblib.dump(model, model_path)\n",
    "    print(\"Model trained and saved to file.\")\n",
    "\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:51:21.379 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "def save_results(system, name):\n",
    "    run = system(pt_dataset.get_topics('text'))\n",
    "    persist_and_normalize_run(run, system_name=name, default_output='../runs')\n",
    "    os.rename('../runs/run.txt', \"../runs/\"+name+\".txt\")\n",
    "\n",
    "# run = rf_pipe(pt_dataset.get_topics('text'))\n",
    "# persist_and_normalize_run(run, system_name=\"rf_pipe\", default_output='../runs')\n",
    "save_results(rf_pipe, 'trained with js_kls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_bm25_grid_search_run(index, output_dir, queries):\n",
    "#     \"\"\"\n",
    "#         defaults: http://terrier.org/docs/current/javadoc/org/terrier/matching/models/BM25.html\n",
    "#         k_1 = 1.2d, k_3 = 8d, b = 0.75d\n",
    "#         We do not tune parameter k_3, as this parameter only impacts queries with reduntant terms.\n",
    "#     \"\"\"\n",
    "#     for b in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "#         for k_1 in [0.5, 1.0, 1.5, 2.0, 2.5]:\n",
    "#             system = f'bm25-b={b}-k_1={k_1}'\n",
    "#             configuration = {\"bm25.b\" : b, \"bm25.k_1\": k_1}\n",
    "#             run_output_dir = output_dir + '/' + system\n",
    "#             !rm -Rf {run_output_dir}\n",
    "#             !mkdir -p {run_output_dir}\n",
    "#             print(f'Run {system}')\n",
    "#             BM25 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls=configuration, verbose=True)\n",
    "#             run = BM25(queries)\n",
    "#             persist_and_normalize_run(run, system, run_output_dir)\n",
    "\n",
    "# run_bm25_grid_search_run(index, 'new-grid-search', pt_dataset.get_topics('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install trectools\n",
    "\n",
    "# from glob import glob\n",
    "# from trectools import TrecRun, TrecQrel, TrecEval\n",
    "# import pandas as pd\n",
    "# from tira.rest_api_client import Client\n",
    "\n",
    "# tira = Client()\n",
    "\n",
    "# def evaluate_run(run_dir, qrels):\n",
    "#     run = TrecRun(run_dir + '/run.txt')\n",
    "#     trec_eval = TrecEval(run, qrels)\n",
    "\n",
    "#     return {\n",
    "#         'run': run.get_runid(),\n",
    "#         'nDCG@10': trec_eval.get_ndcg(depth=10),\n",
    "#         'nDCG@10 (unjudgedRemoved)': trec_eval.get_ndcg(depth=10, removeUnjudged=True),\n",
    "#         'MAP': trec_eval.get_map(depth=10),\n",
    "#         'MRR': trec_eval.get_reciprocal_rank(),\n",
    "#         'P@10': trec_eval.get_precision(depth=10)\n",
    "#     }\n",
    "\n",
    "# def load_qrels(dataset):\n",
    "#     return TrecQrel(tira.download_dataset('ir-lab-sose-2024', dataset, truth_dataset=True) + '/qrels.txt')\n",
    "\n",
    "# training_qrels = load_qrels('ir-acl-anthology-20240504-training')\n",
    "\n",
    "# df = []\n",
    "# for r in glob('grid-search/training/bm25*'):\n",
    "#     df += [evaluate_run(r, training_qrels)]\n",
    "# df = pd.DataFrame(df)\n",
    "# df.sort_values('nDCG@10', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
