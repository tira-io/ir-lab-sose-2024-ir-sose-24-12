{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tira in /usr/local/lib/python3.10/dist-packages (0.0.134)\n",
      "Requirement already satisfied: ir-datasets in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
      "Requirement already satisfied: python-terrier in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tira) (2.1.3)\n",
      "Requirement already satisfied: docker==7.*,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from tira) (7.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tira) (23.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tira) (4.66.1)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /usr/local/lib/python3.10/dist-packages (from tira) (2.31.0)\n",
      "Requirement already satisfied: numpy==1.* in /usr/local/lib/python3.10/dist-packages (from tira) (1.26.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker==7.*,>=7.1.0->tira) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.*,>=2.26->tira) (3.6)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.1.12)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.2.3)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (2.3.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (6.0.1)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.9.3)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (0.1.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (4.3.2)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir-datasets) (3.2.3)\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.2.14)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.2)\n",
      "Requirement already satisfied: chest in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.2.3)\n",
      "Requirement already satisfied: matchpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.1.2)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.6)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier) (10.1.0)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.11.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.7)\n",
      "Requirement already satisfied: nptyping==1.4.4 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.4.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.2)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.14.0)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.3.3)\n",
      "Requirement already satisfied: typish>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.5)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.10/dist-packages (from chest->python-terrier) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier) (2.1.3)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from matchpy->python-terrier) (2.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tira) (2023.3.post1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->python-terrier) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (0.5.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->python-terrier) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install tira ir-datasets python-terrier\n",
    "\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, normalize_run, ir_datasets\n",
    "import pyterrier as pt\n",
    "import os\n",
    "from tira.rest_api_client import Client\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "tira = Client()\n",
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download from the Incubator: https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-sose2024/ir-acl-anthology-20240504-inputs.zip?download=1\n",
      "\tThis is only used for last spot checks before archival to Zenodo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 39.4M/39.4M [00:00<00:00, 72.5MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_datasets/ir-lab-sose-2024/ir-acl-anthology-20240504-training/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents:   0%|          | 0/126958 [00:00<?, ?it/s]/tmp/ipykernel_1323/3628429677.py:17: DeprecationWarning: specifying meta and meta_lengths in IterDictIndexer.index() is deprecated, use constructor instead\n",
      "  index_ref = indexer.index(pt_dataset.get_corpus_iter(),\n",
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents:  70%|███████   | 88956/126958 [00:21<00:07, 4909.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:18:44.183 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (2020.mir_conference-2020.1) - further warnings are suppressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents: 100%|██████████| 126958/126958 [00:27<00:00, 4669.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:18:56.864 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 3 empty documents\n",
      "/root/.tira/extracted_datasets/ir-lab-sose-2024/ir-acl-anthology-20240504-training/truth-data\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from trectools import TrecRun, TrecQrel, TrecEval\n",
    "\n",
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "dataset = 'ir-lab-sose-2024/ir-acl-anthology-20240504-training'\n",
    "pt_dataset = pt.get_dataset('irds:' + dataset)\n",
    "\n",
    "pt_index_path = './terrier-index'\n",
    "\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "  # create the index, using the IterDictIndexer indexer \n",
    "  indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n",
    "\n",
    "  # we give the dataset get_corpus_iter() directly to the indexer\n",
    "  # while specifying the fields to index and the metadata to record\n",
    "  index_ref = indexer.index(pt_dataset.get_corpus_iter(), \n",
    "                            meta=('docno',))\n",
    "\n",
    "else:\n",
    "  # if you already have the index, use it.\n",
    "  index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "ds = tira.download_dataset('ir-lab-sose-2024', dataset, truth_dataset=True)\n",
    "print(ds)\n",
    "\n",
    "def load_qrels(dataset):\n",
    "    return TrecQrel(ds + '/qrels.txt')\n",
    "\n",
    "training_qrels = load_qrels('ir-acl-anthology-20240504-training')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bm25_grid_search_run(index, output_dir, queries):\n",
    "    \"\"\"\n",
    "        defaults: http://terrier.org/docs/current/javadoc/org/terrier/matching/models/BM25.html\n",
    "        k_1 = 1.2d, k_3 = 8d, b = 0.75d\n",
    "        We do not tune parameter k_3, as this parameter only impacts queries with reduntant terms.\n",
    "    \"\"\"\n",
    "    for b in [0.1, 0.2, 0.3, 0.4]:\n",
    "        for k_1 in [0.5]:\n",
    "            system = f'bm25-b={b}-k_1={k_1}'\n",
    "            configuration = {\"bm25.b\" : b, \"bm25.k_1\": k_1}\n",
    "            run_output_dir = output_dir + '/' + system\n",
    "            !rm -Rf {run_output_dir}\n",
    "            !mkdir -p {run_output_dir}\n",
    "            print(f'Run {system}')\n",
    "            BM25 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls=configuration, verbose=True)\n",
    "            run = BM25(queries)\n",
    "            normalize_run(run, system, 1000).to_csv(run_output_dir + '/run.txt', sep=\" \", header=False, index=False)\n",
    "#, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0\n",
    "#, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 47.56q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 45.74q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 39.55q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 44.52q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 41.41q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 42.44q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 38.72q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:01<00:00, 47.12q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run bm25-b=0.1-k_1=1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25):   4%|▍         | 3/68 [00:00<00:02, 27.40q/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset_tira \u001b[38;5;241m=\u001b[39m ir_datasets\u001b[38;5;241m.\u001b[39mload(dataset)\n\u001b[1;32m      2\u001b[0m queries \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_topics(ir_datasets\u001b[38;5;241m.\u001b[39mtopics_file(dataset), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrecxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_bm25_grid_search_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid-search/training\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 16\u001b[0m, in \u001b[0;36mrun_bm25_grid_search_run\u001b[0;34m(index, output_dir, queries)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msystem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m BM25 \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mBatchRetrieve(index, wmodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25\u001b[39m\u001b[38;5;124m\"\u001b[39m, controls\u001b[38;5;241m=\u001b[39mconfiguration, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mBM25\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m normalize_run(run, system, \u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mto_csv(run_output_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/run.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/transformer.py:223\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    Sets up a default method for every transformer, which is aliased to transform() (for DataFrames)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    or transform_iter() (for iterable dictionaries) depending on the type of input. \u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_iter(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/batchretrieve.py:441\u001b[0m, in \u001b[0;36mBatchRetrieve.transform\u001b[0;34m(self, queries)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28miter\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), total\u001b[38;5;241m=\u001b[39mqueries\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m:\n\u001b[0;32m--> 441\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno_provided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocno_provided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocid_provided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocid_provided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores_provided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscores_provided\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(res)\n\u001b[1;32m    444\u001b[0m res_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocid\u001b[39m\u001b[38;5;124m'\u001b[39m ] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/batchretrieve.py:352\u001b[0m, in \u001b[0;36mBatchRetrieve._retrieve_one\u001b[0;34m(self, row, input_results, docno_provided, docid_provided, scores_provided)\u001b[0m\n\u001b[1;32m    349\u001b[0m     srq\u001b[38;5;241m.\u001b[39msetControl(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.terrier.matching.ScoringMatching\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m srq\u001b[38;5;241m.\u001b[39mgetControl(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatching\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# now ask Terrier to run the request\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunSearchRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m result \u001b[38;5;241m=\u001b[39m srq\u001b[38;5;241m.\u001b[39mgetResults()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# check we got all of the expected metadata (if the resultset has a size at all)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_tira = ir_datasets.load(dataset)\n",
    "queries = pt.io.read_topics(ir_datasets.topics_file(dataset), format='trecxml')\n",
    "run_bm25_grid_search_run(index, 'grid-search/training', queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trectools in /usr/local/lib/python3.10/dist-packages (0.0.49)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from trectools) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.10/dist-packages (from trectools) (3.9.0)\n",
      "Requirement already satisfied: scipy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from trectools) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.10/dist-packages (from trectools) (1.3.2)\n",
      "Requirement already satisfied: sarge>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from trectools) (0.1.7.post1)\n",
      "Requirement already satisfied: bs4>=0.0.0.1 in /usr/local/lib/python3.10/dist-packages (from trectools) (0.0.2)\n",
      "Requirement already satisfied: pandas>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from trectools) (2.1.3)\n",
      "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trectools) (1.26.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4>=0.0.0.1->trectools) (4.12.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (10.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (4.53.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.5->trectools) (3.1.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.15.0->trectools) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.15.0->trectools) (2023.3.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.15->trectools) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.15->trectools) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.5->trectools) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4>=0.0.0.1->trectools) (2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mDownload from the Incubator: https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-sose2024/ir-acl-anthology-20240504-truth.zip?download=1\n",
      "\tThis is only used for last spot checks before archival to Zenodo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download: 100%|██████████| 29.6k/29.6k [00:00<00:00, 1.67MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finished. Extract...\n",
      "Extraction finished:  /root/.tira/extracted_datasets/ir-lab-sose-2024/ir-acl-anthology-20240504-training/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n",
      "/usr/local/lib/python3.10/dist-packages/trectools/trec_eval.py:294: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  selection = selection[~selection[\"rel\"].isnull()].groupby(\"query\").first().copy()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m df \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m glob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrid-search/training/bm25*\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     df \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mevaluate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_qrels\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     32\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(df)\n\u001b[1;32m     33\u001b[0m df_sorted \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnDCG@10\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mevaluate_run\u001b[0;34m(run_dir, qrels)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_run\u001b[39m(run_dir, qrels):\n\u001b[0;32m---> 16\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mTrecRun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/run.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     trec_eval \u001b[38;5;241m=\u001b[39m TrecEval(run, qrels)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m: run\u001b[38;5;241m.\u001b[39mget_runid(),\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnDCG@10\u001b[39m\u001b[38;5;124m'\u001b[39m: trec_eval\u001b[38;5;241m.\u001b[39mget_ndcg(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP@10\u001b[39m\u001b[38;5;124m'\u001b[39m: trec_eval\u001b[38;5;241m.\u001b[39mget_precision(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     26\u001b[0m     }\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trectools/trec_run.py:22\u001b[0m, in \u001b[0;36mTrecRun.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/trectools/trec_run.py:58\u001b[0m, in \u001b[0;36mTrecRun.read_run\u001b[0;34m(self, filename, run_header)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Enforce string type on q0 column (if present)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_data:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Enforce string type on query column (if present)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/astype.py:96\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     95\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_string_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_na_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n",
      "File \u001b[0;32mlib.pyx:747\u001b[0m, in \u001b[0;36mpandas._libs.lib.ensure_string_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mlib.pyx:819\u001b[0m, in \u001b[0;36mpandas._libs.lib.ensure_string_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!pip3 install trectools\n",
    "\n",
    "from trectools import TrecRun, TrecQrel, TrecEval\n",
    "from tira.rest_api_client import Client\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "tira = Client()\n",
    "\n",
    "def load_qrels(dataset):\n",
    "    return TrecQrel(tira.download_dataset('ir-lab-sose-2024', dataset, truth_dataset=True) + '/qrels.txt')\n",
    "\n",
    "training_qrels = load_qrels('ir-acl-anthology-20240504-test')\n",
    "\n",
    "\n",
    "def evaluate_run(run_dir, qrels):\n",
    "    run = TrecRun(run_dir + '/run.txt')\n",
    "    trec_eval = TrecEval(run, qrels)\n",
    "\n",
    "    return {\n",
    "        'run': run.get_runid(),\n",
    "        'nDCG@10': trec_eval.get_ndcg(depth=10),\n",
    "        'nDCG@10 (unjudgedRemoved)': trec_eval.get_ndcg(depth=10, removeUnjudged=True),\n",
    "        'MAP': trec_eval.get_map(depth=10),\n",
    "        'MRR': trec_eval.get_reciprocal_rank(),\n",
    "        'P@10': trec_eval.get_precision(depth=10)\n",
    "    }\n",
    "\n",
    "\n",
    "df = []\n",
    "for r in glob('grid-search/training/bm25*'):\n",
    "    df += [evaluate_run(r, training_qrels)]\n",
    "df = pd.DataFrame(df)\n",
    "df_sorted = df.sort_values('nDCG@10', ascending=False)\n",
    "print(df_sorted)\n",
    "best_configuration = df_sorted['run'].values[0]\n",
    "best_b = best_configuration.split(\"-\")[1].split(\"=\")[1]\n",
    "best_k_1 = best_configuration.split(\"-\")[2].split(\"=\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", controls= {\"bm25.b\" : best_b, \"bm25.k_1\": best_k_1})\n",
    "sdm = pt.rewrite.SDM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the expansions\n",
    "dataset_tira = ir_datasets.load(dataset)\n",
    "queries = pt.io.read_topics(ir_datasets.topics_file(dataset), format='trecxml')\n",
    "\n",
    "import pandas as pd\n",
    "from pyterrier.apply import generic\n",
    "\n",
    "def load_llm_transformer(transformer_name):\n",
    "    ret = pd.read_pickle('/app/baseline-retrieval-system/llm_transformers/'+transformer_name)\n",
    "    cols = [i for i in ret.columns if i not in ['qid']]\n",
    "    ret = {str(i['qid']): i for _, i in ret.iterrows()}\n",
    "    def __transform_df(df):\n",
    "            df = df.copy()\n",
    "            for col in cols:\n",
    "                df['llm_expansion_' + col] = df['qid'].apply(lambda i: ret[str(i)][col])\n",
    "            return df\n",
    "    return generic(__transform_df)\n",
    "\n",
    "# llm expansions with gpt\n",
    "gpt_sq_fs = load_llm_transformer('gpt_sq_fs')\n",
    "gpt_sq_zs = load_llm_transformer('gpt_sq_zs')\n",
    "\n",
    "# llm expansions with llama\n",
    "llama_cot = load_llm_transformer('llama_cot')\n",
    "llama_sq_zs = load_llm_transformer('llama_sq_zs')\n",
    "\n",
    "# llm expansions with flan-ul2\n",
    "flan_sq_fs = load_llm_transformer('flan_sq_fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pt_dataset.get_topics(variant='title')\n",
    "\n",
    "tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "\n",
    "def pt_tokenize(text):\n",
    "    return ' '.join(tokeniser.getTokens(text))\n",
    "\n",
    "def expand_query(topic):\n",
    "  ret = ' '.join([topic['query'], topic['query'], topic['query'],  topic['query'],  topic['query'], topic['llm_expansion_query']])\n",
    "\n",
    "  # apply the tokenization\n",
    "  return pt_tokenize(ret)\n",
    "\n",
    "# we wrap this into an pyterrier transformer\n",
    "# Documentation: https://pyterrier.readthedocs.io/en/latest/apply.html\n",
    "pt_expand_query = pt.apply.query(expand_query)\n",
    "\n",
    "\n",
    "pipeline_gpt_sq_fs = (gpt_sq_fs >> pt_expand_query) >> bm25\n",
    "pipeline_gpt_sq_zs = (gpt_sq_zs >> pt_expand_query) >> bm25\n",
    "\n",
    "pipeline_llama_cot = (llama_cot >> pt_expand_query) >> bm25\n",
    "pipeline_llama_sq_zs = (llama_sq_zs >> pt_expand_query) >> bm25\n",
    "\n",
    "pipeline_flan_sq_fs = (flan_sq_fs >> pt_expand_query) >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
    "    \n",
    "topics = pt_dataset.get_topics(variant='title')\n",
    "\n",
    "SEED=42\n",
    "\n",
    "!pip3 install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
    "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)\n",
    "\n",
    "ltr_feats1 = bm25 >> pt.text.get_text(pt_dataset, [\"text\", \"doc_id\"]) >> (\n",
    "    pt.BatchRetrieve(index, wmodel=\"Js_KLs\")\n",
    "    ** # KL Expansion\n",
    "    pt.BatchRetrieve(index, wmodel=\"BM25\", controls={\"qe\":\"on\", \"qemodel\" : \"KL\"})\n",
    "    ** # ChatGPT Similiar Queries Few Shot\n",
    "    pipeline_gpt_sq_fs\n",
    "    ** # ChatGPT Similiar Queries Zero shot\n",
    "    pipeline_gpt_sq_zs\n",
    "    ** # Llama-2 Chain of Thought\n",
    "    pipeline_llama_cot\n",
    "    ** # Llama-2 Similiar Queries Zero shot\n",
    "    pipeline_llama_sq_zs\n",
    "    ** # Flan-UL2 Similiar Queries Few Shot\n",
    "    pipeline_flan_sq_fs\n",
    ")\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames=[\"Js_KLs\", \"KL\", \"gpt_sq_fs\", \"gpt_sq_zs\", \"llama_cot\", \"llama_sq_zs\", \"flan_sq_fs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "!pip3 install joblib\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "trained_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(model)\n",
    "trained_pipe.fit(train_topics, pt_dataset.get_qrels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The run file is normalized outside the TIRA sandbox, I will store it at \"../runs\".\n",
      "Done. run file is stored under \"../runs/run.txt\".\n"
     ]
    }
   ],
   "source": [
    "run = trained_pipe(pt_dataset.get_topics('text'))\n",
    "persist_and_normalize_run(run, system_name=\"RandomForestRegressor\", default_output='../runs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
