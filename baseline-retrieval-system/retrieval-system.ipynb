{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run, ir_datasets\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "from pyterrier_pisa import PisaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "# Create a REST client to the TIRA platform for retrieving the pre-indexed data.\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510cf02807fc4c2aacc3d24970a3888a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ir-lab-sose-2024/ir-acl-anthology-20240504-training documents:   0%|          | 0/126958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pyterrier_pisa/__init__.py:144: UserWarning: text_field not specified; indexing all str fields: ['text']\n",
      "  warn(f'text_field not specified; indexing all str fields: {text_field}')\n",
      "/usr/local/lib/python3.10/dist-packages/pyterrier_pisa/indexers.py:38: UserWarning: Removing index\n",
      "  warn(f'Removing {str(path)}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-15 13:12:12.407] [info] [Batch 1] Processed documents [100000, 126958)\n",
      "[2024-06-15 13:12:26.592] [info] [Batch 0] Processed documents [0, 100000)\n",
      "[2024-06-15 13:12:26.640] [info] Merging titles\n",
      "[2024-06-15 13:12:26.662] [info] Creating document lexicon\n",
      "[2024-06-15 13:12:26.678] [info] Merging URLs\n",
      "[2024-06-15 13:12:26.680] [info] Collecting terms\n",
      "[2024-06-15 13:12:26.718] [info] Writing terms\n",
      "[2024-06-15 13:12:26.738] [info] Mapping terms\n",
      "[2024-06-15 13:12:26.751] [info] Remapping IDs\n",
      "[2024-06-15 13:12:27.145] [info] Concatenating batches\n",
      "[2024-06-15 13:12:27.580] [info] Success.\n",
      "[2024-06-15 13:12:27.605] [info] Inverting [0, 100000)\n",
      "[2024-06-15 13:12:29.447] [info] Inverting [100000, 126958)\n",
      "[2024-06-15 13:12:30.357] [info] Number of terms: 100128\n",
      "[2024-06-15 13:12:30.357] [info] Number of documents: 126958\n",
      "[2024-06-15 13:12:30.357] [info] Number of postings: 7914234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PisaIndex('./index')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "# We are using Pisa Index to index the dataset\n",
    "index = PisaIndex('./index', overwrite=True)\n",
    "\n",
    "index.index(pt_dataset.get_corpus_iter())\n",
    "\n",
    "# get all topics of training dataset\n",
    "#topics = pt_dataset.get_topics()\n",
    "#topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We now do Query expansion in order to improve retrieval effectiveness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('text', 'title', 'query', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.479671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  ndcg_cut_5\n",
       "0  BM25    0.479671"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = index.bm25()\n",
    "\n",
    "#(bm25 >> pt.text.get_text(pt_dataset, 'text')).search('retrieval')\n",
    "pt.Experiment([bm25], pt_dataset.get_topics(), pt_dataset.get_qrels(), eval_metrics=['ndcg_cut_5'], names=['BM25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "index_location is current a <class 'pyterrier_pisa.PisaIndex'>,\n        while it needs to be an Index, an IndexRef, a string that can be\n        resolved to an index location (e.g. path/to/index/data.properties),\n        or an pyterrier.index.TerrierIndexer object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pt\u001b[38;5;241m.\u001b[39mstarted():\n\u001b[1;32m      2\u001b[0m     pt\u001b[38;5;241m.\u001b[39minit(boot_packages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcom.github.terrierteam:terrier-prf:-SNAPSHOT\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m bo1_expansion \u001b[38;5;241m=\u001b[39m bm25 \u001b[38;5;241m>>\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBo1QueryExpansion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m bm25_bo1 \u001b[38;5;241m=\u001b[39m bo1_expansion \u001b[38;5;241m>>\u001b[39m bm25\n\u001b[1;32m      6\u001b[0m pt\u001b[38;5;241m.\u001b[39mExperiment([bm25_bo1], pt_dataset\u001b[38;5;241m.\u001b[39mget_topics(), pt_dataset\u001b[38;5;241m.\u001b[39mget_qrels(), eval_metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndcg_cut_5\u001b[39m\u001b[38;5;124m'\u001b[39m], names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBM25 >> Bo1 >> BM25\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/rewrite.py:329\u001b[0m, in \u001b[0;36mBo1QueryExpansion.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    index_like: the Terrier index to use.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    fb_terms(int): number of terms to add to the query. Terrier's default setting is 10 expansion terms.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    fb_docs(int): number of feedback documents to consider. Terrier's default setting is 3 feedback documents.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqemodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBo1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 329\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/rewrite.py:303\u001b[0m, in \u001b[0;36mDFRQueryExpansion.__init__\u001b[0;34m(self, qemodel, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, qemodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBo1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqemodel \u001b[38;5;241m=\u001b[39m qemodel\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/rewrite.py:207\u001b[0m, in \u001b[0;36mQueryExpansion.__init__\u001b[0;34m(self, index_like, fb_terms, fb_docs, qeclass, verbose, properties, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqe \u001b[38;5;241m=\u001b[39m qeclass\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexref \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_index_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_like\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    209\u001b[0m     pt\u001b[38;5;241m.\u001b[39mApplicationSetup\u001b[38;5;241m.\u001b[39msetProperty(k, \u001b[38;5;28mstr\u001b[39m(v))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/batchretrieve.py:76\u001b[0m, in \u001b[0;36m_parse_index_like\u001b[0;34m(index_location)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m JIR\u001b[38;5;241m.\u001b[39mof(index_location\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JIR\u001b[38;5;241m.\u001b[39mof(index_location)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mindex_location is current a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(index_location)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124m    while it needs to be an Index, an IndexRef, a string that can be\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124m    resolved to an index location (e.g. path/to/index/data.properties),\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124m    or an pyterrier.index.TerrierIndexer object\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: index_location is current a <class 'pyterrier_pisa.PisaIndex'>,\n        while it needs to be an Index, an IndexRef, a string that can be\n        resolved to an index location (e.g. path/to/index/data.properties),\n        or an pyterrier.index.TerrierIndexer object"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
    "\n",
    "bo1_expansion = bm25 >> pt.rewrite.Bo1QueryExpansion(index)\n",
    "bm25_bo1 = bo1_expansion >> bm25\n",
    "pt.Experiment([bm25_bo1], pt_dataset.get_topics(), pt_dataset.get_qrels(), eval_metrics=['ndcg_cut_5'], names=['BM25 >> Bo1 >> BM25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 126958 documents.\n",
      "\n",
      "Query:  1\n",
      "\tText:\t\tretrieval system improving effectiveness\n",
      "\tDescrition:\tWhat papers focus on improving the effectiveness of a retrieval system?\n",
      "\tNarrative:\tRelevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.\n",
      "\n",
      "Query:  2\n",
      "\tText:\t\tmachine learning language identification\n",
      "\tDescrition:\tWhat papers are about machine learning for language identification?\n",
      "\tNarrative:\tRelevant papers include research on methods of machine learning for language identification or how to improve those methods. Papers that focus on other methods for language identification or the usaged of machine learning not for language identification are not relevant.\n",
      "\n",
      "Query:  3\n",
      "\tText:\t\tsocial media detect self-harm\n",
      "\tDescrition:\tWhich papers focus on how to recognize signs of self-harm in people's social media posts?\n",
      "\tNarrative:\tRelevant papers include research on early detection of self-harm on social media platforms such as Facebook, Instagram, Reddit, Twitter and co. Papers that addresses mental health issues like depression or anorexia are not relevant. Furthermore, papers that deal with self-harm but are not related to social media are also not relevant.\n"
     ]
    }
   ],
   "source": [
    "pt_dataset1 = ir_datasets.load('ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "print('The dataset has', len(list(pt_dataset1.docs_iter())), 'documents.')\n",
    "for query in list(pt_dataset1.queries_iter())[:3]:\n",
    "    print('\\nQuery: ', query.query_id)\n",
    "\n",
    "    print('\\tText:\\t\\t' + query.default_text())\n",
    "    print('\\tDescrition:\\t' + query.description)\n",
    "    print('\\tNarrative:\\t' + query.narrative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
